{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom as pdcm\n",
    "import pylab\n",
    "import os,cv2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage import color\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(\"F:/project/\"))\n",
    "#input_path = \"F:/project/\"\n",
    "data_path = 'D:/project/dataset'\n",
    "#data_path = 'D:/project/dataset/d2'\n",
    "#data_path = 'D:/project/dataset/d3'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': 56} ) #max: 1 gpu, 56 cpu\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-negative\n",
      "\n",
      "Loaded the images of dataset-positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_data_list=[]\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        #print(data_path + '/'+ dataset + '/'+ img)\n",
    "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(32,32))  #model 1 and 2 and 3\n",
    "        #input_img_resize=cv2.resize(input_img,(48,48))  #model 4\n",
    "        img_data_list.append(input_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15500, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)\n",
    "plt.imshow( img_data[0])\n",
    "img_data = img_data.reshape(img_data.shape[0], 32, 32, 1)  #model 1 and 2 and 3\n",
    "#img_data = img_data.reshape(img_data.shape[0], 48, 48, 1)  #model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.ones(15500,dtype='int64') # d1 and d2\n",
    "#labels = np.ones(5500,dtype='int64') #d3\n",
    "\n",
    "labels[0:8000]=0\n",
    "labels[8000:]=1\n",
    "# labels[0:3000]=0\n",
    "# labels[3000:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Normal', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (3100, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Y = np_utils.to_categorical(labels, 2)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "print('test shape', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,1)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "#Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# C1 Convolutional Layer\n",
    "#model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(32,32,1), padding=\"same\"))\n",
    "# S2 Pooling Layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# C3 Convolutional Layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# S4 Pooling Layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# C5 Fully Connected Convolutional Layer\n",
    "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "#Flatten the CNN output so that we can connect it with fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# FC6 Fully Connected Layer\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "\n",
    "#Output Layer with softmax activation\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 26, 26, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 281,378\n",
      "Trainable params: 281,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "batch_size = 128\n",
    "#print('test shape', x_test.shape)\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/5\n",
      "12400/12400 [==============================] - 35s 3ms/step - loss: 0.2713 - acc: 0.8758 - val_loss: 0.3346 - val_acc: 0.8471\n",
      "Epoch 2/5\n",
      "12400/12400 [==============================] - 36s 3ms/step - loss: 0.2594 - acc: 0.8835 - val_loss: 0.3332 - val_acc: 0.8506\n",
      "Epoch 3/5\n",
      "12400/12400 [==============================] - 38s 3ms/step - loss: 0.2500 - acc: 0.8900 - val_loss: 0.3639 - val_acc: 0.8471\n",
      "Epoch 4/5\n",
      "12400/12400 [==============================] - 39s 3ms/step - loss: 0.2453 - acc: 0.8903 - val_loss: 0.3579 - val_acc: 0.8476\n",
      "Epoch 5/5\n",
      "12400/12400 [==============================] - 39s 3ms/step - loss: 0.2289 - acc: 0.8981 - val_loss: 0.3731 - val_acc: 0.8421\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m9_v1_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m9_v2_nd.h5') #20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 82.71%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v8p2_nd.h5\")\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"wts_m9_v2_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m9_v2_nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"wts_m9_v3_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m9_v3_nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction tp:\n",
      " 385 tn:\n",
      " 5\n",
      "total: 390\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "num_channel=1\n",
    "model.load_weights(\"wts_m8_v8p2_nd.h5\")\n",
    "data_path = 'D:/intern/chest_xray/test/PNEUMONIA/'\n",
    "img_list=os.listdir('D:/intern/chest_xray/test/PNEUMONIA/')\n",
    "    #print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "total = 0\n",
    "for img in img_list:\n",
    "    test_image=cv2.imread(data_path + '/'+ img )\n",
    "# Testing a new image\n",
    "#test_image = cv2.imread(NORMAL2-IM-1440-0001.jpeg')\n",
    "    test_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "    test_image=cv2.resize(test_image,(32,32))\n",
    "    test_image = np.array(test_image)\n",
    "    test_image = test_image.astype('float32')\n",
    "    test_image /= 255\n",
    "        #print (test_image.shape)\n",
    "   \n",
    "    if num_channel==1:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=3) \n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "\t\t\n",
    "    else:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image=np.rollaxis(test_image,2,0)\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "\t\t\n",
    "# Predicting the test image\n",
    "    \n",
    "    prediction = model.predict(test_image)\n",
    "    #print('Prediction Score:\\n',prediction[0])\n",
    "    #print(model.predict_classes(test_image))\n",
    "    if prediction[0][0]>prediction[0][1]:\n",
    "        tn = tn + 1\n",
    "        #print(names[0])\n",
    "        \n",
    "    else :\n",
    "        tp = tp + 1\n",
    "    total = total+1\n",
    "print('prediction tp:\\n', tp,\"tn:\\n\",tn)\n",
    "print(\"total:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}