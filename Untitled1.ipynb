{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom as pdcm\n",
    "import pylab\n",
    "import os,cv2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from skimage import color\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(\"F:/project/\"))\n",
    "#input_path = \"F:/project/\"\n",
    "data_path = 'D:\\project\\dataset'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0 , 'CPU': 56} ) #max: 1 gpu, 56 cpu\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-negative\n",
      "\n",
      "Loaded the images of dataset-positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_data_list=[]\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        #print(data_path + '/'+ dataset + '/'+ img)\n",
    "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize=cv2.resize(input_img,(64,64))  #model 1 and 2 and 3\n",
    "        #input_img_resize=cv2.resize(input_img,(48,48))  #model 4\n",
    "        #input_img_resize=cv2.resize(input_img,(32,32))\n",
    "        img_data_list.append(input_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15500, 64, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)\n",
    "plt.imshow( img_data[0])\n",
    "#img_data = img_data.reshape(img_data.shape[0], 32, 32, 1) \n",
    "img_data = img_data.reshape(img_data.shape[0], 64, 64, 1)  #model 1 and 2 and 3\n",
    "#img_data = img_data.reshape(img_data.shape[0], 48, 48, 1)  #model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.ones(15500,dtype='int64')\n",
    "\n",
    "labels[0:8000]=0\n",
    "labels[8000:]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Normal', 'PNEUMONIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape (3100, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Y = np_utils.to_categorical(labels, 2)\n",
    "\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "print('test shape', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"======================= MODEL 1=======================\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(16, (5, 5), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 22, 22, 16)        12816     \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 20, 20, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              590848    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 629,170\n",
      "Trainable params: 629,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "#print('test shape', x_test.shape)\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/10\n",
      "\r",
      "  128/12400 [..............................] - ETA: 16s - loss: 0.3047 - acc: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400/12400 [==============================] - 22s 2ms/step - loss: 0.3793 - acc: 0.8246 - val_loss: 0.3890 - val_acc: 0.8160\n",
      "Epoch 2/10\n",
      "12400/12400 [==============================] - 24s 2ms/step - loss: 0.3679 - acc: 0.8321 - val_loss: 0.3790 - val_acc: 0.8258\n",
      "Epoch 3/10\n",
      "12400/12400 [==============================] - 24s 2ms/step - loss: 0.3632 - acc: 0.8336 - val_loss: 0.3900 - val_acc: 0.8295\n",
      "Epoch 4/10\n",
      "12400/12400 [==============================] - 25s 2ms/step - loss: 0.3534 - acc: 0.8385 - val_loss: 0.3839 - val_acc: 0.8274\n",
      "Epoch 5/10\n",
      "12400/12400 [==============================] - 25s 2ms/step - loss: 0.3473 - acc: 0.8401 - val_loss: 0.3725 - val_acc: 0.8319\n",
      "Epoch 6/10\n",
      "12400/12400 [==============================] - 25s 2ms/step - loss: 0.3392 - acc: 0.8402 - val_loss: 0.3708 - val_acc: 0.8290\n",
      "Epoch 7/10\n",
      "12400/12400 [==============================] - 24s 2ms/step - loss: 0.3317 - acc: 0.8466 - val_loss: 0.3635 - val_acc: 0.8352\n",
      "Epoch 8/10\n",
      "12400/12400 [==============================] - 24s 2ms/step - loss: 0.3236 - acc: 0.8514 - val_loss: 0.3808 - val_acc: 0.8223\n",
      "Epoch 9/10\n",
      "12400/12400 [==============================] - 25s 2ms/step - loss: 0.3148 - acc: 0.8541 - val_loss: 0.3730 - val_acc: 0.8268\n",
      "Epoch 10/10\n",
      "12400/12400 [==============================] - 25s 2ms/step - loss: 0.3137 - acc: 0.8533 - val_loss: 0.3723 - val_acc: 0.8335\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v1_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=10, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v1_nd.h5')# 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/10\n",
      "12400/12400 [==============================] - 23s 2ms/step - loss: 0.3032 - acc: 0.8606 - val_loss: 0.3809 - val_acc: 0.8323\n",
      "Epoch 2/10\n",
      "12400/12400 [==============================] - 25s 2ms/step - loss: 0.2934 - acc: 0.8646 - val_loss: 0.3990 - val_acc: 0.8234\n",
      "Epoch 3/10\n",
      "12400/12400 [==============================] - 26s 2ms/step - loss: 0.2849 - acc: 0.8671 - val_loss: 0.3817 - val_acc: 0.8229\n",
      "Epoch 4/10\n",
      "12400/12400 [==============================] - 27s 2ms/step - loss: 0.2848 - acc: 0.8675 - val_loss: 0.3963 - val_acc: 0.8285\n",
      "Epoch 5/10\n",
      "12400/12400 [==============================] - 26s 2ms/step - loss: 0.2730 - acc: 0.8742 - val_loss: 0.4045 - val_acc: 0.8244\n",
      "Epoch 6/10\n",
      "12400/12400 [==============================] - 26s 2ms/step - loss: 0.2604 - acc: 0.8830 - val_loss: 0.4133 - val_acc: 0.8203\n",
      "Epoch 7/10\n",
      "12400/12400 [==============================] - 27s 2ms/step - loss: 0.2577 - acc: 0.8816 - val_loss: 0.4127 - val_acc: 0.8177\n",
      "Epoch 8/10\n",
      "12400/12400 [==============================] - 27s 2ms/step - loss: 0.2528 - acc: 0.8853 - val_loss: 0.4154 - val_acc: 0.8181\n",
      "Epoch 9/10\n",
      "12400/12400 [==============================] - 26s 2ms/step - loss: 0.2343 - acc: 0.8946 - val_loss: 0.4279 - val_acc: 0.8113\n",
      "Epoch 10/10\n",
      "12400/12400 [==============================] - 27s 2ms/step - loss: 0.2278 - acc: 0.8986 - val_loss: 0.4468 - val_acc: 0.8150\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v12_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=10, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v12_nd.h5') #15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"======================= MODEL 2=======================\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,1)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 10, 10, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 281,378\n",
      "Trainable params: 281,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "#print('test shape', x_test.shape)\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11250 samples, validate on 3750 samples\n",
      "Epoch 1/5\n",
      "11250/11250 [==============================] - 92s 8ms/step - loss: 0.5512 - acc: 0.7147 - val_loss: 0.4847 - val_acc: 0.7745\n",
      "Epoch 2/5\n",
      "11250/11250 [==============================] - 91s 8ms/step - loss: 0.4733 - acc: 0.7753 - val_loss: 0.4516 - val_acc: 0.7921\n",
      "Epoch 3/5\n",
      "11250/11250 [==============================] - 91s 8ms/step - loss: 0.4425 - acc: 0.7869 - val_loss: 0.4498 - val_acc: 0.7897\n",
      "Epoch 4/5\n",
      "11250/11250 [==============================] - 91s 8ms/step - loss: 0.4121 - acc: 0.8073 - val_loss: 0.4143 - val_acc: 0.8119\n",
      "Epoch 5/5\n",
      "11250/11250 [==============================] - 92s 8ms/step - loss: 0.4036 - acc: 0.8116 - val_loss: 0.3991 - val_acc: 0.8199\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(\"wts_m8_v2_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v2_nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11250 samples, validate on 3750 samples\n",
      "Epoch 1/10\n",
      "11250/11250 [==============================] - 91s 8ms/step - loss: 0.3903 - acc: 0.8138 - val_loss: 0.4044 - val_acc: 0.8200\n",
      "Epoch 2/10\n",
      "11250/11250 [==============================] - 90s 8ms/step - loss: 0.3866 - acc: 0.8196 - val_loss: 0.3871 - val_acc: 0.8263\n",
      "Epoch 3/10\n",
      "11250/11250 [==============================] - 92s 8ms/step - loss: 0.3736 - acc: 0.8240 - val_loss: 0.3843 - val_acc: 0.8279\n",
      "Epoch 4/10\n",
      "11250/11250 [==============================] - 92s 8ms/step - loss: 0.3642 - acc: 0.8281 - val_loss: 0.3777 - val_acc: 0.8277\n",
      "Epoch 5/10\n",
      "11250/11250 [==============================] - 91s 8ms/step - loss: 0.3582 - acc: 0.8292 - val_loss: 0.3886 - val_acc: 0.8212\n",
      "Epoch 6/10\n",
      "11250/11250 [==============================] - 91s 8ms/step - loss: 0.3586 - acc: 0.8355 - val_loss: 0.3770 - val_acc: 0.8264\n",
      "Epoch 7/10\n",
      "11250/11250 [==============================] - 92s 8ms/step - loss: 0.3548 - acc: 0.8345 - val_loss: 0.3813 - val_acc: 0.8229\n",
      "Epoch 8/10\n",
      "11250/11250 [==============================] - 91s 8ms/step - loss: 0.3475 - acc: 0.8341 - val_loss: 0.3851 - val_acc: 0.8233\n",
      "Epoch 9/10\n",
      "11250/11250 [==============================] - 94s 8ms/step - loss: 0.3412 - acc: 0.8394 - val_loss: 0.3789 - val_acc: 0.8273\n",
      "Epoch 10/10\n",
      "11250/11250 [==============================] - 92s 8ms/step - loss: 0.3355 - acc: 0.8411 - val_loss: 0.3669 - val_acc: 0.8359\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v2_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=10, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v2_nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.1546 - acc: 0.9583 - val_loss: 0.5032 - val_acc: 0.8000\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.1491 - acc: 0.9396 - val_loss: 0.5137 - val_acc: 0.8000\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 0.1243 - acc: 0.9563 - val_loss: 0.5057 - val_acc: 0.8167\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.1038 - acc: 0.9750 - val_loss: 0.5252 - val_acc: 0.8250\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.0854 - acc: 0.9875 - val_loss: 0.5630 - val_acc: 0.8167\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v2_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v2_nd.h5') # 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"======================= MODEL 4=======================\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 3\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,1)))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 24, 24, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 22, 22, 32)        4640      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 428,834\n",
      "Trainable params: 428,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "#print('test shape', x_test.shape)\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11250 samples, validate on 3750 samples\n",
      "Epoch 1/10\n",
      "11250/11250 [==============================] - 107s 10ms/step - loss: 0.3661 - acc: 0.8289 - val_loss: 0.3851 - val_acc: 0.8221\n",
      "Epoch 2/10\n",
      "11250/11250 [==============================] - 108s 10ms/step - loss: 0.3682 - acc: 0.8269 - val_loss: 0.3827 - val_acc: 0.8276\n",
      "Epoch 3/10\n",
      "11250/11250 [==============================] - 114s 10ms/step - loss: 0.3565 - acc: 0.8340 - val_loss: 0.3799 - val_acc: 0.8311\n",
      "Epoch 4/10\n",
      "11250/11250 [==============================] - 107s 10ms/step - loss: 0.3579 - acc: 0.8301 - val_loss: 0.3834 - val_acc: 0.8297\n",
      "Epoch 5/10\n",
      "11250/11250 [==============================] - 107s 9ms/step - loss: 0.3504 - acc: 0.8362 - val_loss: 0.3845 - val_acc: 0.8284\n",
      "Epoch 6/10\n",
      "11250/11250 [==============================] - 106s 9ms/step - loss: 0.3498 - acc: 0.8381 - val_loss: 0.3884 - val_acc: 0.8261\n",
      "Epoch 7/10\n",
      "11250/11250 [==============================] - 107s 9ms/step - loss: 0.3423 - acc: 0.8415 - val_loss: 0.3778 - val_acc: 0.8324\n",
      "Epoch 8/10\n",
      "11250/11250 [==============================] - 107s 9ms/step - loss: 0.3396 - acc: 0.8426 - val_loss: 0.3795 - val_acc: 0.8323\n",
      "Epoch 9/10\n",
      "11250/11250 [==============================] - 106s 9ms/step - loss: 0.3335 - acc: 0.8456 - val_loss: 0.3829 - val_acc: 0.8249\n",
      "Epoch 10/10\n",
      "11250/11250 [==============================] - 108s 10ms/step - loss: 0.3292 - acc: 0.8482 - val_loss: 0.3805 - val_acc: 0.8321\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v4_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=10, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v4_nd.h5') # epochs 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"======================= MODEL 3=======================\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 44, 44, 128)       3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 18, 18, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 32)          18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 425,314\n",
      "Trainable params: 425,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "#print('test shape', x_test.shape)\"\"\"\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 0.0651 - acc: 0.9750 - val_loss: 0.5323 - val_acc: 0.8500\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 3s 15ms/step - loss: 0.0588 - acc: 0.9917 - val_loss: 0.5814 - val_acc: 0.8333\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 4s 15ms/step - loss: 0.0391 - acc: 0.9917 - val_loss: 0.5363 - val_acc: 0.8500\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 4s 16ms/step - loss: 0.0326 - acc: 0.9917 - val_loss: 0.5669 - val_acc: 0.8333\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 0.0289 - acc: 0.9958 - val_loss: 0.6156 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v3_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=5, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v3_nd.h5') # epochs 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'======================= MODEL 5======================='"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"======================= MODEL 5=======================\n",
    "overfitting badly \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(48,48,1), filters=16, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#model.add(Conv2D(filters=192, kernel_size=(3,3)))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 46, 46, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 22, 22, 96)        13920     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 22, 22, 96)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 22, 22, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 10, 10, 128)       110720    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12800)             51200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,814,786\n",
      "Trainable params: 1,789,186\n",
      "Non-trainable params: 25,600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 3s 13ms/step - loss: 0.7221 - acc: 0.7292 - val_loss: 0.6064 - val_acc: 0.7500\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.3581 - acc: 0.8458 - val_loss: 0.4924 - val_acc: 0.7833\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.2977 - acc: 0.8750 - val_loss: 0.4815 - val_acc: 0.7833\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.2612 - acc: 0.8917 - val_loss: 0.4910 - val_acc: 0.7667\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.2101 - acc: 0.9250 - val_loss: 0.5188 - val_acc: 0.7833\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.1500 - acc: 0.9583 - val_loss: 0.5922 - val_acc: 0.7667\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.1322 - acc: 0.9458 - val_loss: 0.7058 - val_acc: 0.7833\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0958 - acc: 0.9708 - val_loss: 0.8433 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.0711 - acc: 0.9833 - val_loss: 1.0157 - val_acc: 0.7333\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 0.0521 - acc: 1.0000 - val_loss: 1.2317 - val_acc: 0.7333\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.load_weights(\"wts_m8_v5_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=10, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v5_nd.h5') # epochs 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'======================= MODEL 6======================='"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"======================= MODEL 6=======================\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(48,48,1), filters=96, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#model.add(Conv2D(filters=192, kernel_size=(3,3)))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=48, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 46, 46, 96)        960       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 46, 46, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 22, 22, 32)        27680     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 10, 10, 48)        13872     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4800)              19200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               614528    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 676,498\n",
      "Trainable params: 666,898\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/3\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 0.0241 - acc: 0.9958 - val_loss: 0.6367 - val_acc: 0.8167\n",
      "Epoch 2/3\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 0.0268 - acc: 0.9917 - val_loss: 0.6622 - val_acc: 0.8167\n",
      "Epoch 3/3\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 0.0419 - acc: 0.9833 - val_loss: 0.6417 - val_acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.load_weights(\"wts_m8_v6_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=3, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v6_nd.h5') #epochs 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\soft\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:29: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction tp:\n",
      " 76 tn:\n",
      " 158\n",
      "total: 234\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "num_channel=1\n",
    "model.load_weights(\"wts_m8_v1_nd.h5\")\n",
    "data_path = 'F:/intern/chest_xray/test/NORMAL/'\n",
    "img_list=os.listdir('F:/intern/chest_xray/test/NORMAL/')\n",
    "    #print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "total = 0\n",
    "for img in img_list:\n",
    "    test_image=cv2.imread(data_path + '/'+ img )\n",
    "# Testing a new image\n",
    "#test_image = cv2.imread(NORMAL2-IM-1440-0001.jpeg')\n",
    "    test_image=cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "    test_image=cv2.resize(test_image,(64,64))\n",
    "    test_image = np.array(test_image)\n",
    "    test_image = test_image.astype('float32')\n",
    "    test_image /= 255\n",
    "        #print (test_image.shape)\n",
    "   \n",
    "    if num_channel==1:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=3) \n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "\t\t\n",
    "    else:\n",
    "        if K.image_dim_ordering()=='th':\n",
    "            test_image=np.rollaxis(test_image,2,0)\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "        else:\n",
    "            test_image= np.expand_dims(test_image, axis=0)\n",
    "                #print (test_image.shape)\n",
    "\t\t\n",
    "# Predicting the test image\n",
    "    \n",
    "    prediction = model.predict(test_image)\n",
    "    #print('Prediction Score:\\n',prediction[0])\n",
    "    #print(model.predict_classes(test_image))\n",
    "    if prediction[0][0]>prediction[0][1]:\n",
    "        tn = tn + 1\n",
    "        #print(names[0])\n",
    "        \n",
    "    else :\n",
    "        tp = tp + 1\n",
    "    total = total+1\n",
    "print('prediction tp:\\n', tp,\"tn:\\n\",tn)\n",
    "print(\"total:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 9, 9, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 324,626\n",
      "Trainable params: 323,346\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/15\n",
      "12400/12400 [==============================] - 26s 2ms/step - loss: 0.3140 - acc: 0.8542 - val_loss: 0.3917 - val_acc: 0.8163\n",
      "Epoch 2/15\n",
      "12400/12400 [==============================] - 29s 2ms/step - loss: 0.3098 - acc: 0.8602 - val_loss: 0.3661 - val_acc: 0.8265\n",
      "Epoch 3/15\n",
      "12400/12400 [==============================] - 30s 2ms/step - loss: 0.3128 - acc: 0.8582 - val_loss: 0.3898 - val_acc: 0.8273\n",
      "Epoch 4/15\n",
      "12400/12400 [==============================] - 31s 2ms/step - loss: 0.3079 - acc: 0.8606 - val_loss: 0.3670 - val_acc: 0.8300\n",
      "Epoch 5/15\n",
      "12400/12400 [==============================] - 30s 2ms/step - loss: 0.3024 - acc: 0.8617 - val_loss: 0.3808 - val_acc: 0.8279\n",
      "Epoch 6/15\n",
      "12400/12400 [==============================] - 34s 3ms/step - loss: 0.2997 - acc: 0.8603 - val_loss: 0.3791 - val_acc: 0.8260\n",
      "Epoch 7/15\n",
      "12400/12400 [==============================] - 33s 3ms/step - loss: 0.2996 - acc: 0.8634 - val_loss: 0.4040 - val_acc: 0.8102\n",
      "Epoch 8/15\n",
      "12400/12400 [==============================] - 30s 2ms/step - loss: 0.2955 - acc: 0.8640 - val_loss: 0.3761 - val_acc: 0.8182\n",
      "Epoch 9/15\n",
      "12400/12400 [==============================] - 34s 3ms/step - loss: 0.2849 - acc: 0.8676 - val_loss: 0.3669 - val_acc: 0.8289\n",
      "Epoch 10/15\n",
      "12400/12400 [==============================] - 34s 3ms/step - loss: 0.2882 - acc: 0.8682 - val_loss: 0.4184 - val_acc: 0.8065\n",
      "Epoch 11/15\n",
      " 8960/12400 [====================>.........] - ETA: 9s - loss: 0.2788 - acc: 0.8745"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3097b5f5547d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"wts_m8_v7_nd.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wts_m8_v7_nd.h5'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#epochs 18\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.load_weights(\"wts_m8_v7_nd.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=15, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m8_v7_nd.h5') #epochs 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4 = Sequential()\n",
    "cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "cnn4.add(BatchNormalization())\n",
    "\n",
    "cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn4.add(Dropout(0.25))\n",
    "\n",
    "cnn4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.25))\n",
    "\n",
    "cnn4.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn4.add(Dropout(0.25))\n",
    "\n",
    "cnn4.add(Flatten())\n",
    "\n",
    "cnn4.add(Dense(512, activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.5))\n",
    "\n",
    "cnn4.add(Dense(128, activation='relu'))\n",
    "cnn4.add(BatchNormalization())\n",
    "cnn4.add(Dropout(0.5))\n",
    "\n",
    "cnn4.add(Dense(2, activation='softmax'))\n",
    "\n",
    "cnn4.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "#view rawfashion-mnist-cnn4conv.py hosted with  by GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,220,514\n",
      "Trainable params: 1,218,722\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn4.summary()\n",
    "cnn4.get_config()\n",
    "cnn4.layers[0].get_config()\n",
    "cnn4.layers[0].input_shape\t\t\t\n",
    "cnn4.layers[0].output_shape\t\t\t\n",
    "cnn4.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/10\n",
      "12400/12400 [==============================] - 61s 5ms/step - loss: 0.3896 - acc: 0.8200 - val_loss: 0.3890 - val_acc: 0.8106\n",
      "Epoch 2/10\n",
      "12400/12400 [==============================] - 68s 6ms/step - loss: 0.3783 - acc: 0.8236 - val_loss: 0.3952 - val_acc: 0.8139\n",
      "Epoch 3/10\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.3730 - acc: 0.8270 - val_loss: 0.4153 - val_acc: 0.8081\n",
      "Epoch 4/10\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.3595 - acc: 0.8312 - val_loss: 0.5037 - val_acc: 0.7726\n",
      "Epoch 5/10\n",
      "12400/12400 [==============================] - 70s 6ms/step - loss: 0.3624 - acc: 0.8331 - val_loss: 0.3838 - val_acc: 0.8213\n",
      "Epoch 6/10\n",
      "12400/12400 [==============================] - 74s 6ms/step - loss: 0.3581 - acc: 0.8338 - val_loss: 0.4223 - val_acc: 0.8013\n",
      "Epoch 7/10\n",
      "12400/12400 [==============================] - 74s 6ms/step - loss: 0.3531 - acc: 0.8367 - val_loss: 0.3941 - val_acc: 0.8142\n",
      "Epoch 8/10\n",
      "12400/12400 [==============================] - 74s 6ms/step - loss: 0.3452 - acc: 0.8396 - val_loss: 0.3971 - val_acc: 0.8152\n",
      "Epoch 9/10\n",
      "12400/12400 [==============================] - 73s 6ms/step - loss: 0.3477 - acc: 0.8413 - val_loss: 0.4097 - val_acc: 0.8068\n",
      "Epoch 10/10\n",
      "12400/12400 [==============================] - 72s 6ms/step - loss: 0.3414 - acc: 0.8425 - val_loss: 0.4361 - val_acc: 0.8048\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "cnn4.load_weights(\"wts_m8_v8_nd.h5\")\n",
    "hist=cnn4.fit(x_train, y_train, batch_size=batch_size, nb_epoch=10, verbose=1, validation_data=(x_test, y_test))\n",
    "cnn4.save_weights('wts_m8_v8_nd.h5') #epochs 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 9, 9, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 122,242\n",
      "Trainable params: 122,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "#print('test shape', x_test.shape)\n",
    "\n",
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/20\n",
      "  512/12400 [>.............................] - ETA: 2s - loss: 0.3033 - acc: 0.8662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400/12400 [==============================] - 3s 253us/step - loss: 0.3244 - acc: 0.8506 - val_loss: 0.3707 - val_acc: 0.8287: 1s - l\n",
      "Epoch 2/20\n",
      "12400/12400 [==============================] - 3s 251us/step - loss: 0.3207 - acc: 0.8507 - val_loss: 0.3803 - val_acc: 0.8316\n",
      "Epoch 3/20\n",
      "12400/12400 [==============================] - 3s 259us/step - loss: 0.3168 - acc: 0.8531 - val_loss: 0.4075 - val_acc: 0.8106\n",
      "Epoch 4/20\n",
      "12400/12400 [==============================] - 3s 277us/step - loss: 0.3171 - acc: 0.8558 - val_loss: 0.3741 - val_acc: 0.8305\n",
      "Epoch 5/20\n",
      "12400/12400 [==============================] - 3s 272us/step - loss: 0.3151 - acc: 0.8543 - val_loss: 0.3801 - val_acc: 0.8258\n",
      "Epoch 6/20\n",
      "12400/12400 [==============================] - 4s 285us/step - loss: 0.3084 - acc: 0.8555 - val_loss: 0.4118 - val_acc: 0.8271\n",
      "Epoch 7/20\n",
      "12400/12400 [==============================] - 4s 286us/step - loss: 0.3069 - acc: 0.8590 - val_loss: 0.3840 - val_acc: 0.8237\n",
      "Epoch 8/20\n",
      "12400/12400 [==============================] - 4s 297us/step - loss: 0.3052 - acc: 0.8602 - val_loss: 0.4068 - val_acc: 0.8279\n",
      "Epoch 9/20\n",
      "12400/12400 [==============================] - 4s 302us/step - loss: 0.2990 - acc: 0.8639 - val_loss: 0.3784 - val_acc: 0.8253\n",
      "Epoch 10/20\n",
      "12400/12400 [==============================] - 4s 302us/step - loss: 0.2990 - acc: 0.8611 - val_loss: 0.4116 - val_acc: 0.8221\n",
      "Epoch 11/20\n",
      "12400/12400 [==============================] - 4s 291us/step - loss: 0.2983 - acc: 0.8636 - val_loss: 0.3950 - val_acc: 0.8235\n",
      "Epoch 12/20\n",
      "12400/12400 [==============================] - 4s 294us/step - loss: 0.2990 - acc: 0.8640 - val_loss: 0.3719 - val_acc: 0.8276\n",
      "Epoch 13/20\n",
      "12400/12400 [==============================] - 4s 309us/step - loss: 0.2872 - acc: 0.8682 - val_loss: 0.3878 - val_acc: 0.8323\n",
      "Epoch 14/20\n",
      "12400/12400 [==============================] - 4s 305us/step - loss: 0.2854 - acc: 0.8709 - val_loss: 0.4018 - val_acc: 0.8277\n",
      "Epoch 15/20\n",
      "12400/12400 [==============================] - 4s 320us/step - loss: 0.2876 - acc: 0.8689 - val_loss: 0.4054 - val_acc: 0.8234\n",
      "Epoch 16/20\n",
      "12400/12400 [==============================] - 4s 301us/step - loss: 0.2836 - acc: 0.8705 - val_loss: 0.3948 - val_acc: 0.8169\n",
      "Epoch 17/20\n",
      "12400/12400 [==============================] - 4s 321us/step - loss: 0.2772 - acc: 0.8726 - val_loss: 0.4266 - val_acc: 0.8221\n",
      "Epoch 18/20\n",
      "12400/12400 [==============================] - 4s 318us/step - loss: 0.2781 - acc: 0.8725 - val_loss: 0.4281 - val_acc: 0.8127\n",
      "Epoch 19/20\n",
      "12400/12400 [==============================] - 4s 304us/step - loss: 0.2721 - acc: 0.8760 - val_loss: 0.4309 - val_acc: 0.8269\n",
      "Epoch 20/20\n",
      "12400/12400 [==============================] - 4s 304us/step - loss: 0.2700 - acc: 0.8769 - val_loss: 0.4102 - val_acc: 0.8223\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m5_v2.h5\")\n",
    "hist=model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=20, verbose=1, validation_data=(x_test, y_test))\n",
    "model.save_weights('wts_m5_v2.h5')#epochs 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rajesh Kumar Sharma\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "#Instantiate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# C1 Convolutional Layer\n",
    "#model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28,28,1), padding=\"same\"))\n",
    "model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(32,32,1), padding=\"same\"))\n",
    "# S2 Pooling Layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
    "\n",
    "# C3 Convolutional Layer\n",
    "model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "\n",
    "# S4 Pooling Layer\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "\n",
    "# C5 Fully Connected Convolutional Layer\n",
    "model.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "#Flatten the CNN output so that we can connect it with fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# FC6 Fully Connected Layer\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "\n",
    "#Output Layer with softmax activation\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 31, 31, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9720)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                816564    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 170       \n",
      "=================================================================\n",
      "Total params: 867,426\n",
      "Trainable params: 867,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/50\n",
      "12400/12400 [==============================] - 10s 837us/step - loss: 0.3674 - acc: 0.8327 - val_loss: 0.3876 - val_acc: 0.8242\n",
      "Epoch 2/50\n",
      "12400/12400 [==============================] - 11s 908us/step - loss: 0.3672 - acc: 0.8322 - val_loss: 0.3912 - val_acc: 0.8223\n",
      "Epoch 3/50\n",
      "12400/12400 [==============================] - 12s 928us/step - loss: 0.3666 - acc: 0.8338 - val_loss: 0.3844 - val_acc: 0.8245\n",
      "Epoch 4/50\n",
      "12400/12400 [==============================] - 12s 955us/step - loss: 0.3653 - acc: 0.8320 - val_loss: 0.3866 - val_acc: 0.8210\n",
      "Epoch 5/50\n",
      "12400/12400 [==============================] - 12s 992us/step - loss: 0.3656 - acc: 0.8332 - val_loss: 0.3874 - val_acc: 0.8268\n",
      "Epoch 6/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3639 - acc: 0.8325 - val_loss: 0.3838 - val_acc: 0.8210\n",
      "Epoch 7/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3621 - acc: 0.8342 - val_loss: 0.3882 - val_acc: 0.8226\n",
      "Epoch 8/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3615 - acc: 0.8357 - val_loss: 0.3928 - val_acc: 0.8168\n",
      "Epoch 9/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3608 - acc: 0.8334 - val_loss: 0.3849 - val_acc: 0.8255\n",
      "Epoch 10/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3605 - acc: 0.8336 - val_loss: 0.3829 - val_acc: 0.8239\n",
      "Epoch 11/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3600 - acc: 0.8350 - val_loss: 0.3829 - val_acc: 0.8245\n",
      "Epoch 12/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3592 - acc: 0.8325 - val_loss: 0.3839 - val_acc: 0.8219\n",
      "Epoch 13/50\n",
      "12400/12400 [==============================] - 12s 992us/step - loss: 0.3591 - acc: 0.8351 - val_loss: 0.3849 - val_acc: 0.8187\n",
      "Epoch 14/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3564 - acc: 0.8382 - val_loss: 0.3852 - val_acc: 0.8216\n",
      "Epoch 15/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3575 - acc: 0.8368 - val_loss: 0.3912 - val_acc: 0.8229\n",
      "Epoch 16/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3559 - acc: 0.8373 - val_loss: 0.3822 - val_acc: 0.8248\n",
      "Epoch 17/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3558 - acc: 0.8368 - val_loss: 0.3799 - val_acc: 0.8239\n",
      "Epoch 18/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3545 - acc: 0.8366 - val_loss: 0.3851 - val_acc: 0.8261\n",
      "Epoch 19/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3540 - acc: 0.8369 - val_loss: 0.3860 - val_acc: 0.8219\n",
      "Epoch 20/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3536 - acc: 0.8371 - val_loss: 0.3914 - val_acc: 0.8194\n",
      "Epoch 21/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3525 - acc: 0.8407 - val_loss: 0.3833 - val_acc: 0.8223\n",
      "Epoch 22/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3524 - acc: 0.8387 - val_loss: 0.3860 - val_acc: 0.8232\n",
      "Epoch 23/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3509 - acc: 0.8390 - val_loss: 0.3806 - val_acc: 0.8226\n",
      "Epoch 24/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3505 - acc: 0.8423 - val_loss: 0.3829 - val_acc: 0.8216\n",
      "Epoch 25/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3502 - acc: 0.8393 - val_loss: 0.3800 - val_acc: 0.8255\n",
      "Epoch 26/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3504 - acc: 0.8388 - val_loss: 0.3814 - val_acc: 0.8229\n",
      "Epoch 27/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3479 - acc: 0.8401 - val_loss: 0.3804 - val_acc: 0.8245\n",
      "Epoch 28/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3476 - acc: 0.8406 - val_loss: 0.3820 - val_acc: 0.8206\n",
      "Epoch 29/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3471 - acc: 0.8410 - val_loss: 0.3846 - val_acc: 0.8229\n",
      "Epoch 30/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3463 - acc: 0.8410 - val_loss: 0.3859 - val_acc: 0.8187\n",
      "Epoch 31/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3455 - acc: 0.8436 - val_loss: 0.3796 - val_acc: 0.8255\n",
      "Epoch 32/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3442 - acc: 0.8437 - val_loss: 0.3805 - val_acc: 0.8219\n",
      "Epoch 33/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3433 - acc: 0.8429 - val_loss: 0.3830 - val_acc: 0.8226\n",
      "Epoch 34/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3440 - acc: 0.8431 - val_loss: 0.3794 - val_acc: 0.8232\n",
      "Epoch 35/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3420 - acc: 0.8437 - val_loss: 0.3845 - val_acc: 0.8187\n",
      "Epoch 36/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3419 - acc: 0.8435 - val_loss: 0.3940 - val_acc: 0.8203\n",
      "Epoch 37/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3405 - acc: 0.8471 - val_loss: 0.3801 - val_acc: 0.8235\n",
      "Epoch 38/50\n",
      "12400/12400 [==============================] - 12s 1ms/step - loss: 0.3400 - acc: 0.8434 - val_loss: 0.3809 - val_acc: 0.8223\n",
      "Epoch 39/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3402 - acc: 0.8469 - val_loss: 0.3820 - val_acc: 0.8248\n",
      "Epoch 40/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3389 - acc: 0.8460 - val_loss: 0.3801 - val_acc: 0.8213\n",
      "Epoch 41/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3403 - acc: 0.8455 - val_loss: 0.3799 - val_acc: 0.8232\n",
      "Epoch 42/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3383 - acc: 0.8440 - val_loss: 0.3811 - val_acc: 0.8219\n",
      "Epoch 43/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3362 - acc: 0.8494 - val_loss: 0.3808 - val_acc: 0.8226\n",
      "Epoch 44/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3367 - acc: 0.8476 - val_loss: 0.3859 - val_acc: 0.8216\n",
      "Epoch 45/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3357 - acc: 0.8470 - val_loss: 0.3911 - val_acc: 0.8197\n",
      "Epoch 46/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3357 - acc: 0.8479 - val_loss: 0.3878 - val_acc: 0.8197\n",
      "Epoch 47/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3341 - acc: 0.8490 - val_loss: 0.3861 - val_acc: 0.8213\n",
      "Epoch 48/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3339 - acc: 0.8494 - val_loss: 0.3853 - val_acc: 0.8255\n",
      "Epoch 49/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3328 - acc: 0.8489 - val_loss: 0.3813 - val_acc: 0.8229\n",
      "Epoch 50/50\n",
      "12400/12400 [==============================] - 13s 1ms/step - loss: 0.3321 - acc: 0.8512 - val_loss: 0.3812 - val_acc: 0.8197\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v8_nd.h5\")\n",
    "hist = model.fit(x=x_train,y=y_train, epochs=50, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "model.save_weights('wts_m8_v8_nd.h5') #150 = 81.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/20\n",
      "12400/12400 [==============================] - 15s 1ms/step - loss: 0.3339 - acc: 0.8484 - val_loss: 0.3825 - val_acc: 0.8274\n",
      "Epoch 2/20\n",
      "12400/12400 [==============================] - 16s 1ms/step - loss: 0.3314 - acc: 0.8483 - val_loss: 0.3809 - val_acc: 0.8258\n",
      "Epoch 3/20\n",
      "12400/12400 [==============================] - 16s 1ms/step - loss: 0.3310 - acc: 0.8498 - val_loss: 0.3849 - val_acc: 0.8258\n",
      "Epoch 4/20\n",
      "12400/12400 [==============================] - 16s 1ms/step - loss: 0.3301 - acc: 0.8502 - val_loss: 0.3823 - val_acc: 0.8261\n",
      "Epoch 5/20\n",
      "12400/12400 [==============================] - 17s 1ms/step - loss: 0.3289 - acc: 0.8529 - val_loss: 0.3860 - val_acc: 0.8235\n",
      "Epoch 6/20\n",
      "12400/12400 [==============================] - 17s 1ms/step - loss: 0.3296 - acc: 0.8475 - val_loss: 0.3814 - val_acc: 0.8287\n",
      "Epoch 7/20\n",
      "12400/12400 [==============================] - 19s 2ms/step - loss: 0.3282 - acc: 0.8525 - val_loss: 0.4078 - val_acc: 0.8190\n",
      "Epoch 8/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3272 - acc: 0.8508 - val_loss: 0.3839 - val_acc: 0.8258\n",
      "Epoch 9/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3271 - acc: 0.8532 - val_loss: 0.3811 - val_acc: 0.8265\n",
      "Epoch 10/20\n",
      "12400/12400 [==============================] - 22s 2ms/step - loss: 0.3235 - acc: 0.8533 - val_loss: 0.3833 - val_acc: 0.8261\n",
      "Epoch 11/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3244 - acc: 0.8524 - val_loss: 0.3803 - val_acc: 0.8294\n",
      "Epoch 12/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3220 - acc: 0.8560 - val_loss: 0.3910 - val_acc: 0.8252\n",
      "Epoch 13/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3222 - acc: 0.8511 - val_loss: 0.3895 - val_acc: 0.8213\n",
      "Epoch 14/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3225 - acc: 0.8536 - val_loss: 0.3838 - val_acc: 0.8265\n",
      "Epoch 15/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3204 - acc: 0.8553 - val_loss: 0.3915 - val_acc: 0.8261\n",
      "Epoch 16/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3193 - acc: 0.8537 - val_loss: 0.3819 - val_acc: 0.8290\n",
      "Epoch 17/20\n",
      "12400/12400 [==============================] - 20s 2ms/step - loss: 0.3182 - acc: 0.8572 - val_loss: 0.3857 - val_acc: 0.8268\n",
      "Epoch 18/20\n",
      "12400/12400 [==============================] - 20s 2ms/step - loss: 0.3170 - acc: 0.8581 - val_loss: 0.3868 - val_acc: 0.8245\n",
      "Epoch 19/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3189 - acc: 0.8571 - val_loss: 0.3847 - val_acc: 0.8294\n",
      "Epoch 20/20\n",
      "12400/12400 [==============================] - 21s 2ms/step - loss: 0.3153 - acc: 0.8566 - val_loss: 0.3843 - val_acc: 0.8271\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v8p2_nd.h5\")\n",
    "hist = model.fit(x=x_train,y=y_train, epochs=20, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "model.save_weights('wts_m8_v8p2_nd.h5') #120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\",\n",
    "                 input_shape=(64,64,1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              16778240  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 16,849,762\n",
      "Trainable params: 16,847,522\n",
      "Non-trainable params: 2,240\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.get_config()\n",
    "model.layers[0].get_config()\n",
    "model.layers[0].input_shape\t\t\t\n",
    "model.layers[0].output_shape\t\t\t\n",
    "model.layers[0].get_weights()\n",
    "np.shape(model.layers[0].get_weights()[0])\n",
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12400 samples, validate on 3100 samples\n",
      "Epoch 1/5\n",
      "12400/12400 [==============================] - 332s 27ms/step - loss: 0.3768 - acc: 0.8237 - val_loss: 0.6212 - val_acc: 0.7329\n",
      "Epoch 2/5\n",
      "12400/12400 [==============================] - 342s 28ms/step - loss: 0.3660 - acc: 0.8315 - val_loss: 0.4451 - val_acc: 0.7987\n",
      "Epoch 3/5\n",
      "12400/12400 [==============================] - 339s 27ms/step - loss: 0.3505 - acc: 0.8401 - val_loss: 0.4084 - val_acc: 0.8126\n",
      "Epoch 4/5\n",
      "12400/12400 [==============================] - 356s 29ms/step - loss: 0.3374 - acc: 0.8455 - val_loss: 0.4072 - val_acc: 0.8194\n",
      "Epoch 5/5\n",
      "12400/12400 [==============================] - 348s 28ms/step - loss: 0.3246 - acc: 0.8505 - val_loss: 0.4293 - val_acc: 0.7987\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"wts_m8_v9_nd.h5\")\n",
    "hist = model.fit(x=x_train,y=y_train, epochs=5, batch_size=128, validation_data=(x_test, y_test), verbose=1)\n",
    "model.save_weights('wts_m8_v9_nd.h5') #150 = 81.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
